{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import time as t\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import datetime\n",
    "import sys\n",
    "from lib import sparkStructuredStreaming\n",
    "import os\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up to stream from Kafka topic + read and write from/to Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.5,org.elasticsearch:elasticsearch-spark-20_2.11:7.6.2 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"127.0.0.1:9092\" (local) //\"10.0.0.8:9092\" (BACC)\n",
    "bootstrap = \"127.0.0.1:9092\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .appName(\"KafkaIEXStructuredStreaming\") \\\n",
    "            .master(\"local[*]\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Historical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read historical data from yahoo finance, write into HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol=[\"AAPL\",\"MSFT\",\"AMZN\",\"^IXIC\"]\n",
    "period=\"5d\"\n",
    "interval=\"1m\"\n",
    "hdfs_path = \"hdfs://0.0.0.0:19000\"\n",
    "\n",
    "for symbol in symbol:\n",
    "    sparkStructuredStreaming.history().to_hdfs(symbol, interval, period, sqlContext, hdfs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Momentum Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol=[\"AAPL\",\"MSFT\",\"AMZN\"]\n",
    "#strategy looks at last 120 minutes to calculate average\n",
    "strategy = [\"momentum\",10,120,500]\n",
    "# granularity of historical data\n",
    "interval=\"1m\"\n",
    "hdfs_path = \"hdfs://0.0.0.0:19000\"\n",
    "#start capital\n",
    "startCap = 10000.0\n",
    "# distribution of start-capital between stocks\n",
    "share = [0.4,0.2,0.4]\n",
    "# regulatory trading fee\n",
    "commission = 0.000119\n",
    "# when testing different strategies each one needs individual id\n",
    "depotId = 19\n",
    "# risk free market return, assumed here 0.1% but is not really clear\n",
    "risk_free = 0.001\n",
    "\n",
    "b = sparkStructuredStreaming.backtest()\n",
    "\n",
    "performance = b.performance(depotId, symbol, share, startCap, commission, risk_free, strategy, interval, hdfs_path, sqlContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+----------+-------------+----------+----------+------+--------------------+------------------+\n",
      "|DepotId|     Value|     Alpha|      Beta|Start-Capital|    Profit|Start-Date|Trades|Performance_Strategy|Performance_Nasdaq|\n",
      "+-------+----------+----------+----------+-------------+----------+----------+------+--------------------+------------------+\n",
      "|     15|10303.7...|2.33084...|0.54361...|      10000.0|303.789...|2020-05-06|  8886|          3.03789...|        1.28106...|\n",
      "|     16|10198.9...|1.37842...|0.46724...|      10000.0|198.943...|2020-05-06|  3140|          1.98943...|        1.28106...|\n",
      "|     17|9990.36...|-0.2830...|0.12987...|      10000.0|-9.6356...|2020-05-06|  1281|          -0.0963...|        1.28106...|\n",
      "|     18|10195.3...|0.35966...|1.10370...|      10000.0|195.322...|2020-05-06|    30|          1.95322...|        1.44601...|\n",
      "|     19|10206.9...|2.04189...|0.54230...|      10000.0|206.947...|2020-05-07|  7135|          2.06947...|        0.03115...|\n",
      "|     20|10036.3...|0.33646...|0.52435...|      10000.0|36.3896...|2020-05-07|  1725|          0.36389...|        0.03115...|\n",
      "|     21|10022.0...|0.19363...|0.41392...|      10000.0|22.0198...|2020-05-07|   983|          0.22019...|        0.03115...|\n",
      "|     22|10136.7...|1.15557...|1.09885...|      10000.0|136.773...|2020-05-07|    29|          1.36773...|        0.19517...|\n",
      "+-------+----------+----------+----------+-------------+----------+----------+------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hdfs_path = \"hdfs://0.0.0.0:19000\"\n",
    "df_performance = sqlContext.read.format('parquet').load(hdfs_path+\"/performance\").orderBy(\"DepotId\")\n",
    "df_performance.show(20, truncate=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------+------------------+---------------+\n",
      "|DepotId|Start-Caputal|    Strategy|              ISIN|          Share|\n",
      "+-------+-------------+------------+------------------+---------------+\n",
      "|     15|      10000.0|  momentum10|[AAPL, MSFT, AMZN]|[0.4, 0.2, 0.4]|\n",
      "|     16|      10000.0| momentum120|[AAPL, MSFT, AMZN]|[0.4, 0.2, 0.4]|\n",
      "|     17|      10000.0| momentum500|[AAPL, MSFT, AMZN]|[0.4, 0.2, 0.4]|\n",
      "|     18|      10000.0|Buy and Hold|[AAPL, MSFT, AMZN]|[0.4, 0.2, 0.4]|\n",
      "|     19|      10000.0|  momentum10|[AAPL, MSFT, AMZN]|[0.4, 0.2, 0.4]|\n",
      "|     20|      10000.0| momentum120|[AAPL, MSFT, AMZN]|[0.4, 0.2, 0.4]|\n",
      "|     21|      10000.0| momentum500|[AAPL, MSFT, AMZN]|[0.4, 0.2, 0.4]|\n",
      "|     22|      10000.0|Buy and Hold|[AAPL, MSFT, AMZN]|[0.4, 0.2, 0.4]|\n",
      "+-------+-------------+------------+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_depot = sqlContext.read.format('parquet').load(hdfs_path+\"/depot\")\n",
    "df_depot.orderBy(\"DepotId\").show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Trading Simulation / Performance Evaluation with realtime Streams (Spark Streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream real time quotes from Kafka topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "function simulates realtime trading and writes results into elasticsearch\n",
    "needs a stream that writes new stock prices into \"hdfs://0.0.0.0:19000/realtime/momentum\" \n",
    "and \"hdfs://0.0.0.0:19000/realtime/buyAndHold\"\n",
    "\"\"\"\n",
    "\n",
    "def realtime(symbol, share, startCap, commission, strategy, r, es):\n",
    "    # compare momentum strategy with buy and hold\n",
    "    strategy_b = [r.buy_and_hold,\"buyAndHold\",10]\n",
    "    \n",
    "    # initialize both strategys\n",
    "    init_strategy = r.realtime_init(symbol, share, startCap, commission, strategy, sqlContext)\n",
    "    init_b = r.realtime_init(symbol, share, startCap, commission, strategy_b, sqlContext)\n",
    "    value, datetime, moneyForInvesting_list, moneyInStocks_list, stocksOwned, trades_total = init_strategy\n",
    "    value_b, datetime_b, moneyForInvesting_list_b, moneyInStocks_list_b, stocksOwned_b, trades_total_b = init_b\n",
    "    \n",
    "    while(True):\n",
    "        # update depot and stocksOwned in loop until break\n",
    "        depot_strategy = r.realtime_loop(value, datetime, moneyForInvesting_list, moneyInStocks_list, stocksOwned,\\\n",
    "                                       trades_total, symbol, share, commission, strategy, sqlContext)\n",
    "        depot_b = r.realtime_loop(value_b, datetime_b, moneyForInvesting_list_b, moneyInStocks_list_b, stocksOwned_b,\\\n",
    "                                  trades_total_b, symbol, share, commission, strategy_b, sqlContext)\n",
    "        value, datetime, moneyForInvesting_list, moneyInStocks_list, stocksOwned, trades_total = depot_strategy\n",
    "        value_b, datetime_b, moneyForInvesting_list_b, moneyInStocks_list_b, stocksOwned_b, trades_total_b = depot_b\n",
    "        \n",
    "        # write values into elasticsearch for visualisation\n",
    "        doc = {}\n",
    "        doc['date'] = (datetime_b[0] - timedelta(hours=2,minutes=0)).strftime(\"%Y-%m-%d\"'T'\"%H:%M:%S\")\n",
    "        doc['momentum'] = value\n",
    "        doc['buy and hold'] = value_b\n",
    "        res = es.index(index=\"test\", body=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-86716318ed8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mcommission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.000119\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmomentum_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"momentum\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mrealtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshare\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstartCap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommission\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-5ebcbf4f0ddd>\u001b[0m in \u001b[0;36mrealtime\u001b[1;34m(symbol, share, startCap, commission, strategy, r, es)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mwhile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         depot_strategy = r.realtime_loop(value, datetime, moneyForInvesting_list, moneyInStocks_list, stocksOwned,\\\n\u001b[1;32m---> 11\u001b[1;33m                                        trades_total, symbol, share, commission, strategy, sqlContext)\n\u001b[0m\u001b[0;32m     12\u001b[0m         depot_b = r.realtime_loop(value_b, datetime_b, moneyForInvesting_list_b, moneyInStocks_list_b, stocksOwned_b,\\\n\u001b[0;32m     13\u001b[0m                                   trades_total_b, symbol, share, commission, strategy_b, sqlContext)\n",
      "\u001b[1;32m~\\RAMBO\\kafka_spark_python\\lib\\sparkStructuredStreaming.py\u001b[0m in \u001b[0;36mrealtime_loop\u001b[1;34m(self, value, datetime, moneyForInvesting_list, moneyInStocks_list, stocksOwned, trades_total, symbol, share, commission, strategy, sqlContext)\u001b[0m\n\u001b[0;32m    782\u001b[0m             \u001b[1;31m# filter out right symbol, get latest price\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    783\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 784\u001b[1;33m             \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    785\u001b[0m             \u001b[1;31m# only proceed if there is a new stock price available\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatetime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\spark\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    532\u001b[0m         \"\"\"\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m             \u001b[0msock_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\spark\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[1;32mc:\\spark\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\spark\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m             \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Answer received: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from datetime import timedelta\n",
    "\n",
    "es=Elasticsearch([{'host':'localhost','port':9200}])\n",
    "r = sparkStructuredStreaming.realtime()\n",
    "\n",
    "# same set up as in backtesting\n",
    "symbol=[\"AAPL\",\"MSFT\",\"AMZN\"]\n",
    "share = [0.4,0.2,0.4]\n",
    "startCap = 10000.0\n",
    "commission = 0.000119\n",
    "\n",
    "# choose momentum which worked best in backtesting\n",
    "momentum_str = [r.momentum,\"momentum\",10]\n",
    "\n",
    "\n",
    "realtime(symbol, share, startCap, commission, momentum_str, r, es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
