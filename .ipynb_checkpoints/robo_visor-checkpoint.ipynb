{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import time as t\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *\n",
    "import datetime\n",
    "import sys\n",
    "from lib import sparkStructuredStreaming\n",
    "import os\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from pyspark.sql.window import Window\n",
    "import math as m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up to stream from Kafka topic + read and write from/to Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.11:2.4.5,org.elasticsearch:elasticsearch-spark-20_2.11:7.6.2 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"127.0.0.1:9092\" (local) //\"10.0.0.8:9092\" (BACC)\n",
    "bootstrap = \"127.0.0.1:9092\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .appName(\"KafkaIEXStructuredStreaming\") \\\n",
    "            .master(\"local[*]\") \\\n",
    "            .getOrCreate()\n",
    "\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Backtesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Try different strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  3 of 3 completed\n",
      "[*********************100%***********************]  3 of 3 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  61 of 61 completed\n",
      "\n",
      "4 Failed downloads:\n",
      "- EVHC: No data found for this date range, symbol may be delisted\n",
      "- AET: No data found for this date range, symbol may be delisted\n",
      "- CELG: No data found, symbol may be delisted\n",
      "- ESRX: No data found for this date range, symbol may be delisted\n",
      "[*********************100%***********************]  4 of 4 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "b = sparkStructuredStreaming.backtest()\n",
    "\n",
    "#strategy looks at last 10,120,500... minutes to calculate average\n",
    "strategy_momentum = [[\"1d\",\"momentum\",10,30,60,120,180],[\"5d\",\"momentum\",30,60,120,180,240,300,400,500,600,800]]\n",
    "# mean reverse strategy\n",
    "rsi_buy = 15\n",
    "rsi_sell = 60\n",
    "ibr_buy = 0.2\n",
    "ibr_sell = 0.7 \n",
    "strategy_mean_reverse = [\"mean_reverse\",rsi_buy,rsi_sell,ibr_buy,ibr_sell,3,5,8,10,14,20]\n",
    "# granularity of historical data\n",
    "interval_momentum=\"1m\"\n",
    "interval_mean_reverse = \"1d\"\n",
    "hdfs_path = \"hdfs://0.0.0.0:19000\"\n",
    "#start capital\n",
    "startCap = 10000.0\n",
    "# regulatory trading fee\n",
    "commission = 0.000119\n",
    "# risk free market return, assumed here 0.1% but is not really clear\n",
    "risk_free = 0.001\n",
    "\n",
    "for strategy in strategy_momentum:\n",
    "    performance = b.performance(startCap, commission, risk_free, strategy[1:], interval_momentum, strategy[0], hdfs_path, sqlContext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+----+-------------+------+----------+----------+------+--------------------+------------------+\n",
      "|DepotId|   Value|Alpha|Beta|Start-Capital|Profit|Start-Date|  End-Date|Trades|Performance_Strategy|Performance_S&P500|\n",
      "+-------+--------+-----+----+-------------+------+----------+----------+------+--------------------+------------------+\n",
      "|      1|  9982.6|-0.86|0.52|      10000.0| -17.4|2020-05-15|2020-05-15|   385|               -0.17|              1.31|\n",
      "|      2|  9969.9| -1.1|0.61|      10000.0| -30.1|2020-05-15|2020-05-15|   204|                -0.3|              1.31|\n",
      "|      3|10124.74|  0.3|0.72|      10000.0|124.74|2020-05-15|2020-05-15|   134|                1.25|              1.31|\n",
      "|      4|10063.99|-0.37|0.77|      10000.0| 63.99|2020-05-15|2020-05-15|   126|                0.64|              1.31|\n",
      "|      5|10095.55|-0.31|0.96|      10000.0| 95.55|2020-05-15|2020-05-15|    79|                0.96|              1.31|\n",
      "|      6|10075.39|-0.19|0.72|      10000.0| 75.39|2020-05-15|2020-05-15|     4|                0.75|              1.31|\n",
      "|      7|10300.65| 3.88|0.62|      10000.0|300.65|2020-05-11|2020-05-15|   388|                3.01|             -1.41|\n",
      "|      8|10717.97| 7.72|0.39|      10000.0|717.97|2020-05-11|2020-05-15|    65|                7.18|             -1.41|\n",
      "|      9|10565.94| 6.31|0.46|      10000.0|565.94|2020-05-11|2020-05-13|    22|                5.66|             -1.41|\n",
      "|     10|10057.95|  1.5|0.66|      10000.0| 57.95|2020-05-11|2020-05-11|    18|                0.58|             -1.41|\n",
      "|     11|10057.95|  1.5|0.66|      10000.0| 57.95|2020-05-11|2020-05-11|    18|                0.58|             -1.41|\n",
      "|     12|10057.95|  1.5|0.66|      10000.0| 57.95|2020-05-11|2020-05-11|    18|                0.58|             -1.41|\n",
      "|     13|10057.95|  1.5|0.66|      10000.0| 57.95|2020-05-11|2020-05-11|    18|                0.58|             -1.41|\n",
      "|     14|10057.95|  1.5|0.66|      10000.0| 57.95|2020-05-11|2020-05-11|    18|                0.58|             -1.41|\n",
      "|     15|10057.95|  1.5|0.66|      10000.0| 57.95|2020-05-11|2020-05-11|    18|                0.58|             -1.41|\n",
      "|     16|10057.95|  1.5|0.66|      10000.0| 57.95|2020-05-11|2020-05-11|    18|                0.58|             -1.41|\n",
      "|     17|10660.35| 7.68|0.77|      10000.0|660.35|2020-05-11|2020-05-15|     6|                 6.6|             -1.41|\n",
      "+-------+--------+-----+----+-------------+------+----------+----------+------+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hdfs_path = \"hdfs://0.0.0.0:19000\"\n",
    "df_performance = sqlContext.read.format('parquet').load(hdfs_path+\"/performance\").orderBy(\"DepotId\")\n",
    "df_performance.show(80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+------------+----------------------+-------------------------------------------------------------+\n",
      "|DepotId|Start-Caputal|Strategy    |ISIN                  |Share                                                        |\n",
      "+-------+-------------+------------+----------------------+-------------------------------------------------------------+\n",
      "|1      |10000.0      |momentum10  |[CTL, T, VZ]          |[0.3333333333333333, 0.3333333333333333, 0.33333333333333337]|\n",
      "|2      |10000.0      |momentum30  |[CTL, T, VZ]          |[0.3333333333333333, 0.3333333333333333, 0.33333333333333337]|\n",
      "|3      |10000.0      |momentum60  |[CTL, T, VZ]          |[0.3333333333333333, 0.3333333333333333, 0.33333333333333337]|\n",
      "|4      |10000.0      |momentum120 |[CTL, T, VZ]          |[0.3333333333333333, 0.3333333333333333, 0.33333333333333337]|\n",
      "|5      |10000.0      |momentum180 |[CTL, T, VZ]          |[0.3333333333333333, 0.3333333333333333, 0.33333333333333337]|\n",
      "|6      |10000.0      |Buy and Hold|[CTL, T, VZ]          |[0.3333333333333333, 0.3333333333333333, 0.33333333333333337]|\n",
      "|7      |10000.0      |momentum30  |[HUM, ILMN, ABBV, MRK]|[0.25, 0.25, 0.25, 0.25]                                     |\n",
      "|8      |10000.0      |momentum60  |[HUM, ILMN, ABBV, MRK]|[0.25, 0.25, 0.25, 0.25]                                     |\n",
      "|9      |10000.0      |momentum120 |[HUM, ILMN, ABBV, MRK]|[0.25, 0.25, 0.25, 0.25]                                     |\n",
      "|10     |10000.0      |momentum180 |[HUM, ILMN, ABBV, MRK]|[0.25, 0.25, 0.25, 0.25]                                     |\n",
      "|11     |10000.0      |momentum240 |[HUM, ILMN, ABBV, MRK]|[0.25, 0.25, 0.25, 0.25]                                     |\n",
      "|12     |10000.0      |momentum300 |[HUM, ILMN, ABBV, MRK]|[0.25, 0.25, 0.25, 0.25]                                     |\n",
      "|13     |10000.0      |momentum400 |[HUM, ILMN, ABBV, MRK]|[0.25, 0.25, 0.25, 0.25]                                     |\n",
      "|14     |10000.0      |momentum500 |[HUM, ILMN, ABBV, MRK]|[0.25, 0.25, 0.25, 0.25]                                     |\n",
      "|15     |10000.0      |momentum600 |[HUM, ILMN, ABBV, MRK]|[0.25, 0.25, 0.25, 0.25]                                     |\n",
      "|16     |10000.0      |momentum800 |[HUM, ILMN, ABBV, MRK]|[0.25, 0.25, 0.25, 0.25]                                     |\n",
      "|17     |10000.0      |Buy and Hold|[HUM, ILMN, ABBV, MRK]|[0.25, 0.25, 0.25, 0.25]                                     |\n",
      "+-------+-------------+------------+----------------------+-------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_depot = sqlContext.read.format('parquet').load(hdfs_path+\"/depot\")\n",
    "df_depot.orderBy(\"DepotId\").show(70, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Trading Simulation / Performance Evaluation with realtime Streams (Spark Streaming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stream real time quotes from Kafka topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-14 15:32:36 9999.999524 10013.43286\n",
      "2020-05-14 15:33:59 10001.299524000002 10016.42286\n",
      "2020-05-14 15:35:09 10008.359524 10027.41286\n",
      "2020-05-14 15:35:24 10008.359524 10038.66286\n",
      "2020-05-14 15:37:45 10008.359524 10047.70286\n",
      "2020-05-14 15:38:10 10008.359524 10042.442860000001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e1522578a8c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrealtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshare\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstartCap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommission\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqlContext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\RAMBO\\kafka_spark_python\\lib\\sparkStructuredStreaming.py\u001b[0m in \u001b[0;36mrealtime\u001b[1;34m(self, symbol, share, startCap, commission, strategy, index, sqlContext)\u001b[0m\n\u001b[0;32m   1014\u001b[0m             \u001b[1;31m# update depot and stocksOwned in loop until break\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1015\u001b[0m             depot_strategy = self.realtime_loop(value, datetime, moneyForInvesting_list, moneyInStocks_list, stocksOwned,\\\n\u001b[1;32m-> 1016\u001b[1;33m                                            trades_total, symbol, share, commission, strategy, sqlContext)\n\u001b[0m\u001b[0;32m   1017\u001b[0m             depot_b = self.realtime_loop(value_b, datetime_b, moneyForInvesting_list_b, moneyInStocks_list_b, stocksOwned_b,\\\n\u001b[0;32m   1018\u001b[0m                                       trades_total_b, symbol, share, commission, strategy_b, sqlContext)\n",
      "\u001b[1;32m~\\RAMBO\\kafka_spark_python\\lib\\sparkStructuredStreaming.py\u001b[0m in \u001b[0;36mrealtime_loop\u001b[1;34m(self, value, datetime, moneyForInvesting_list, moneyInStocks_list, stocksOwned, trades_total, symbol, share, commission, strategy, sqlContext)\u001b[0m\n\u001b[0;32m    979\u001b[0m             \u001b[1;31m# filter out right symbol, get latest price\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m             \u001b[0mdf_pos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m             \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_pos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m             \u001b[1;31m# only proceed if there is a new stock price available\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m             \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatetime\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\spark\\python\\pyspark\\sql\\dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    532\u001b[0m         \"\"\"\n\u001b[0;32m    533\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 534\u001b[1;33m             \u001b[0msock_info\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    535\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPickleSerializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\spark\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1253\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m   1257\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[1;32mc:\\spark\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m    983\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\spark\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m             \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Answer received: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "r = sparkStructuredStreaming.realtime()\n",
    "\n",
    "# same set up as in backtesting\n",
    "symbol, share = # todo: use the ibes which performed best in backtesting\n",
    "\n",
    "startCap = 10000.0\n",
    "commission = 0.000119\n",
    "index = \"trading\"\n",
    "# choose momentum which worked best in backtesting\n",
    "momentum_str = [r.momentum,\"momentum\",10]\n",
    "\n",
    "\n",
    "r.realtime(symbol, share, startCap, commission, momentum_str, index, sqlContext)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
